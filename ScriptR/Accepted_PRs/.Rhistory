ncols(tabela)
ncols(tabela1)
ncol(tabela1)
nrow(tabela1)
tabela1 <- cbind(tabela1, data.frame(Casado = c(FALSE,TRUE,TRUE)))
tabela1
tabela1 <- cbind(tabela1, data.frame(Sexo = c(TRUE,TRUE)))
tabela1 <- cbind(tabela1, data.frame(Sexo = c(TRUE,TRUE))
)
seq(3,5)
seq(from = 3, to = 5)
seq(from = 3, length = 3, by = 0.5)
paste("xyz", 1:10)
paste("xyz", c(2,5,7,"test", 4.5))
paste("xyz", 1:10, sep= "")
paste("xyz", 1:10, sep= ",")
paste ("R is great", c(4,7,45), "and I will love it")
rep(c(3,4,5), 3)
rep(1:10, times = 3)
x<- c(1,2,3)
rep(x, each = 3)
rep(x, each = 3, times =3)
x<- c(4:20)
which(x == 10)
x<-x[-c(5,6)]
x
soma <-function(x) {
x+x
}
soma(10)
y<-soma(5)
y
print(c)
c
multiplica <-function(z,w) {
valor <- z*3
valor <- valor * w
print(valor) #função para imprimir
}
multiplica(5,4)
soma <-function(x,y) {
return(x,y)
}
a,b <- soma(3,2)
a <- soma(3,2)
}
}
soma <-function(x,y) {
return(c(x,y))
}
s<-soma(3,4)
s
a<-1
b<-2
c<-3
if(a!=b & b!=c & c!=a) {cat ("é um triângulo escaleno")}
x<-23
ifelse(x>=0,sqrt(x), "o numero é negativo")
for (i in 1:15) {print (i)}
dados<-c(10,15,9,7,6,12,17)
n<-length(dados)
soma<-0
for (i in 1:n){
soma<-dados[i]+soma
}
media<-soma/n
media
dados <- data.frame(Paises = c("Alemanha", "barbados", "brasil", "cuba", "Egito", "Iraque", "Jamaica", "noruega", "Zimbabue"),
IDH = c(0.920, 0.825,0.730,0.780,0.662,0.590,0.730,0.955,0.397))
dados$Nivel<-0
View(dados)
for(i in 1:9) {
ifelse(dados[i,2] <= 0.534, dados[i,3] <- "baixo",
ifelse(dados[i,2] <= 0.710, dados[i,3] <- "médio",
ifelse(dados[i,2] <= 0.796, dados[i,3] <- "Alto", dados[i,3] <- "Muito Alto")))
}
View(tabela1)
View(dados)
?apply
x <- matrix(c(1:9), nr=3, byrow=T)
apply(x, 1, mean)
a <- list(first=c(1,2), second=4)
a$first
a$second
mtcars
?mtcars
mtcars
mtcars[3,]
mtcars[,2]
mtcars[10,5]
View(mtcars)
head(mtcars)
tail(mtcars)
str(mtcars)
mtcars$carb
attach(mtcars)
sum(wt)
mtcars[,c(1:4)] #seleção de subcolunas
mtcars[1,]
mtcars[,1]
mtcars$mpg
mtcars[1,1]
mtcars[c(1,3), ]
mtcars[c(1:3),c(1,5)]
mtcars[c(1:3),c(1,5)]
x<-subset(mtcars, cyl == 6 & wt > 2.8)
x
write.csv(mtcars, "/Users/igorwiese/Documents/UTFPR/UTFPR_2016/mining_software_repository/R_tutorial/data.csv")
write.csv(mtcars, "/Users/igorwiese/Documents/UTFPR/UTFPR_2016/mining_software_repository/data.csv")
data <- read.csv("/Users/igorwiese/Documents/UTFPR/UTFPR_2016/mining_software_repository/data.csv", sep = ",")
data2 <- read.csv("/Users/igorwiese/Documents/UTFPR/UTFPR_2016/mining_software_repository/data.csv")
View(data2)
data2 <- read.csv("/Users/igorwiese/Documents/UTFPR/UTFPR_2016/mining_software_repository/data.csv", is.na=FALSE)
data2 <- read.csv("/Users/igorwiese/Documents/UTFPR/UTFPR_2016/mining_software_repository/data.csv", is.naOmit)
x<-c(10,12,11,7,8,13,9,10)
y<-c(10,12,111,7,8,13,9,10)
z<-c(10,12,111,7,8,13,9,10,NA)
sum(x)
max(x)
min(x)
range(x)
mean(z, na.rm=T) #precisa desconsiderar valores não identificados no conjunto de dados
mean(y)
median(x)
require(moments)
skewness(mtcars$carb)
hist(mtcars$carb)
skewness(mtcars$am)
hist(mtcars$am)
kurtosis(mtcars$carb)
hist(mtcars$carb)
median(mtcars$carb)
std(mtcars$carb)
stdv(mtcars$carb)
sd(mtcars$carb)
var(x)
var(y)
sd(x)
sd(y)
idade<-c(25,36,77,12,45,89)
renda<-c(1000,1500,2000,1800,500,600)
cv<-function(x){
coef<-sd(x)/mean(x)*100
return(coef)
}
cv(idade)
cv(renda)
summary(mtcars)
library(Hmisc)
describe(mtcars)
library(psych)
describe(mtcars)
describeBy(sat.act,sat.act$gender)
quantile(mtcars$mpg, probs=c(0.10,0.25,0.36)) #calculo dos quartis configurados
plot(mtcars)
hist(mtcars$mpg)
shapiro.test(mtcars$mpg)
four.cyl <- subset(mtcars, cyl == 4)
eight.cyl <- subset(mtcars, cyl == 8)
six.cyl <- subset(mtcars, cyl == 6)
wilcox.test(four.cyl$mpg, eight.cyl$mpg)
library(effsize)
res = cliff.delta(four.cyl$mpg,eight.cyl$mpg,return.dm=TRUE)
print(res)
four.cyl$mpg
eight.cyl$mpg
View(mtcars)
summary(mtcars)
summary(mtcars)
x<-2+2
View(data2)
x<-c(2,3,4,5)
x
x
x<-"Igor"
x
boxplot(mtcars$mpg)
boxplot(mtcars$mpg, main="titulo")
boxplot(mtcars, main="titulo")
hist(mtcars$gear)
install.packages("Rcmdr")
library(Rcmdr)
source("http://scg.sdsu.edu/wp-content/uploads/2013/09/dataprep.r")
library(randomForest)
library(ROCR)
library(nnet)
library(rpart)
# Logistic Regression
logit.fit = glm(income ~.-relationship, family = binomial(logit),data = data$train)
logit.preds = predict(logit.fit,newdata=data$val,type="response")
logit.pred = prediction(logit.preds,data$val$income)
logit.perf = performance(logit.pred,"tpr","fpr")
# Random Forest
bestmtry <- tuneRF(data$train[-13],data$train$income, ntreeTry=100,
stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE, dobest=FALSE)
rf.fit <-randomForest(income~.,data=data$train, mtry=2, ntree=1000,
keep.forest=TRUE, importance=TRUE,test=data$val)
rf.preds = predict(rf.fit,type="prob",newdata=data$val)[,2]
rf.pred = prediction(rf.preds, data$val$income)
rf.perf = performance(rf.pred,"tpr","fpr")
# CART Trees
mycontrol = rpart.control(cp = 0, xval = 10)
tree.fit = rpart(income~., method = "class",data = data$train, control = mycontrol)
tree.fit$cptable
tree.prune = prune(tree.fit,cp=tree.cptarg)
tree.cptarg = sqrt(tree.fit$cptable[8,1]*tree.fit$cptable[9,1])
tree.preds = predict(tree.prune,newdata=data$val,type="prob")[,2]
tree.pred = prediction(tree.preds,data$val$income)
tree.perf = performance(tree.pred,"tpr","fpr")
# Neural Network
nnet.fit = nnet(income~., data=data$train,size=20,maxit=10000,decay=.001)
nnet.preds = predict(nnet.fit,newdata=data$val,type="raw")
nnet.pred = prediction(nnet.preds,data$val$income)
nnet.perf = performance(nnet.pred,"tpr","fpr")
# Plotting ROC Curves
plot(logit.perf,col=2,lwd=2,main="ROC Curve for Classifiers on Adult Dataset")
plot(rf.perf,col=3,lwd=2,add=T)
plot(tree.perf,lwd=2,col=4,add=T)
plot(nnet.perf,lwd=2,col=5,add=T)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
legend("bottomright",col=c(2:5),lwd=2,legend=c("logit","RF","CART","Neural Net"),bty='n')
tree.fit$cptable
tree.cptarg = sqrt(tree.fit$cptable[8,1]*tree.fit$cptable[9,1])
tree.prune = prune(tree.fit,cp=tree.cptarg)
tree.preds = predict(tree.prune,newdata=data$val,type="prob")[,2]
tree.pred = prediction(tree.preds,data$val$income)
tree.perf = performance(tree.pred,"tpr","fpr")
plot(tree.perf,lwd=2,col=4,add=T)
library(survival)
data(diabetes)
library(mclust)
library(ROCR)
library(RWeka)
library(mlbench)
library(party)
data(PimaIndiansDiabetes)
View(PimaIndiansDiabetes)
data(PimaIndiansDiabetes)
trainIndex <- createDataPartition(PimaIndiansDiabetes$diabetes, p = .7, list = FALSE, times = 1)
library(RWeka)
library(mlbench)
trainIndex <- createDataPartition(PimaIndiansDiabetes$diabetes, p = .7, list = FALSE, times = 1)
library(caret)
data(PimaIndiansDiabetes)
trainIndex <- createDataPartition(PimaIndiansDiabetes$diabetes, p = .7, list = FALSE, times = 1)
trainIndex
trainSet <- PimaIndiansDiabetes[ trainIndex,]
testSet  <- PimaIndiansDiabetes[-trainIndex,]
fit <- train(diabetes ~.,PimaIndiansDiabetes, method = "rpart")
str(fit)
plot(fit)
library(rattle)
fancyRpartPlot(fit$finalModel)
fancyRpartPlot(fit$finalModel)
predictions2 <- predict(fit, testSet)
predictions2
testSet$diabetes
cm<-confusionMatrix(predictions2,testSet$diabetes)
cm
cm$table[1,1]
a<-cm$table[1,1]
b<-cm$table[1,2]
c<-cm$table[2,1]
d<-cm$table[2,2]
TP<-d
FP<-c
FN<-b
TN<-a
MCC<-((a*d)-(b*c))/sqrt((a+b)*(a+c)*(d+b)*(d+c))
MCC
TP<-a
FP<-b
FN<-c
TN<-d
precision<-TN/(TN+FN)
precision
recall<-TN/(TN+FP)
recall
f1<-2*((recall*precision)/(recall+precision))
f1
set.seed(7)
library(mlbench)
library(caret)
data(PimaIndiansDiabetes)
correlationMatrix <- cor(PimaIndiansDiabetes[,1:8])
print(correlationMatrix)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.5)
highlyCorrelated
print(highlyCorrelated)
library("amap")
hc <- hcluster(PimaIndiansDiabetes,method = "cor",link = "centroid", nbproc= 1, doubleprecision = TRUE)
hc
hc
hc <- hcluster(PimaIndiansDiabetes,method = "cor",link = "centroid", nbproc= 1, doubleprecision = TRUE)
require(rms)
vcobj = varclus(~., data=PimaIndiansDiabetes,trans="abs")
plot(vcobj)
thresh = 0.7
abline(h = 1 - thresh , col="grey", lty =2)
thresh = 0.55
abline(h = 1 - thresh , col="grey", lty =2)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(diabetes~., data=PimaIndiansDiabetes, method="lvq", preProcess="scale", trControl=control)
importance <- varImp(model, scale=TRUE)
# summarize importance
print(importance)
plot(importance)
results <- rfe(PimaIndiansDiabetes[,1:8], PimaIndiansDiabetes[,9], sizes=c(1:8), rfeControl=control)
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(PimaIndiansDiabetes[,1:8], PimaIndiansDiabetes[,9], sizes=c(1:8), rfeControl=control)
# summarize the results
print(results)
predictors(results)
plot(results, type=c("g", "o"))
library(mlbench)
library(caret)
data(PimaIndiansDiabetes)
# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the LVQ model
set.seed(7)
modelLvq <- train(diabetes~., data=PimaIndiansDiabetes, method="lvq", trControl=control)
# train the GBM model
set.seed(7)
modelGbm <- train(diabetes~., data=PimaIndiansDiabetes, method="gbm", trControl=control, verbose=FALSE)
# train the SVM model
set.seed(7)
modelSvm <- train(diabetes~., data=PimaIndiansDiabetes, method="svmRadial", trControl=control)
1# collect resamples
results <- resamples(list(LVQ=modelLvq, GBM=modelGbm, SVM=modelSvm))
summary(results)
bwplot(results)
source("http://scg.sdsu.edu/wp-content/uploads/2013/09/dataprep.r")
library(randomForest)
library(ROCR)
library(nnet)
library(rpart)
# Logistic Regression
logit.fit = glm(income ~.-relationship, family = binomial(logit),data = data$train)
logit.preds = predict(logit.fit,newdata=data$val,type="response")
source("http://scg.sdsu.edu/wp-content/uploads/2013/09/dataprep.r")
library(mclust)
data(diabetes)
mtcars
View(mtcars)
hist(mpg)
hist(mtcars$mpg)
boxplot(mtcars$mpg)
four.cyl <- subset(mtcars, cyl == 4)
nrow(four.cyl)
eight.cyl <- subset(mtcars, cyl == 8)
nrow(eight.cyl)
six.cyl <- subset(mtcars, cyl == 6)
nrow(six.cyl)
wilcox.test(four.cyl$mpg, eight.cyl$mpg)
summary(eight.cyl)
summary(four.cyl)
#Tamanho de EFEITO!
library(effsize)
## survival analysis
#install.packages("survival")
## survival analysis
library(survival)
survdata <- read.csv("pareshive.csv", header=T, sep=";")
MCC_social<-c(0.59,0.30,0.37,0.66,0.61,0.25,0.58,0.25,0.36,0.17)
F_social<-c(0.70,0.42,0.52,0.76,0.70,0.44,0.64,0.40,0.48,0.34)
F_commits<-c(0.74,0.41,0.58,0.78,0.76,0.40,0.65,0.47,0.55,0.41)
F_numeric<-c(0.75,0.45,0.60,0.80,0.77,0.47,0.69,0.48,0.57,0.44)
MCC_social<-c(0.59,0.30,0.37,0.66,0.61,0.25,0.58,0.25,0.36,0.17)
MCC_commits<-c(0.65,0.27,0.46,0.69,0.69,0.19,0.59,0.34,0.45,0.26)
MCC_numeric<-c(0.65,0.34,0.50,0.72,0.71,0.30,0.68,0.35,0.46,0.33)
wilcox.test(F_commits, F_social)
wilcox.test(F_numeric, F_social)
wilcox.test(F_numeric, F_commits)
wilcox.test(MCC_commits, MCC_social)
wilcox.test(MCC_numeric, MCC_social)
wilcox.test(MCC_numeric, MCC_commits)
library(effsize)
#(treatment, control)
res = cliff.delta(F_commits, F_social,return.dm=TRUE)
print(res)
print(res$dm)
res = cliff.delta(F_numeric, F_social,return.dm=TRUE)
print(res)
res = cliff.delta(F_numeric, F_commits,return.dm=TRUE)
print(res)
res = cliff.delta(MCC_commits, MCC_social, return.dm=TRUE)
print(res)
res = cliff.delta(MCC_numeric, MCC_social,return.dm=TRUE)
print(res)
res = cliff.delta(MCC_numeric, MCC_commits,return.dm=TRUE)
print(res)
F_social<-c(0.70,0.42,0.52,0.76,0.70,0.44,0.64,0.40,0.48,0.34)
F_commits<-c(0.74,0.41,0.58,0.78,0.76,0.40,0.65,0.47,0.55,0.41)
F_numeric<-c(0.75,0.45,0.60,0.80,0.77,0.47,0.69,0.48,0.57,0.44)
MCC_social<-c(0.59,0.30,0.37,0.66,0.61,0.25,0.58,0.25,0.36,0.17)
MCC_commits<-c(0.65,0.27,0.46,0.69,0.69,0.19,0.59,0.34,0.45,0.26)
MCC_numeric<-c(0.65,0.34,0.50,0.72,0.71,0.30,0.68,0.35,0.46,0.33)
wilcox.test(F_commits, F_social)
wilcox.test(F_numeric, F_social)
wilcox.test(F_numeric, F_commits)
wilcox.test(MCC_commits, MCC_social)
wilcox.test(MCC_numeric, MCC_social)
wilcox.test(MCC_numeric, MCC_commits)
library(effsize)
#(treatment, control)
res = cliff.delta(F_commits, F_social,return.dm=TRUE)
print(res)
res = cliff.delta(F_numeric, F_social,return.dm=TRUE)
print(res)
res = cliff.delta(F_numeric, F_commits,return.dm=TRUE)
print(res)
res = cliff.delta(MCC_numeric, MCC_social,return.dm=TRUE)
print(res)
print(res$dm)
res = cliff.delta(MCC_numeric, MCC_commits,return.dm=TRUE)
print(res)
res = cliff.delta(F_numeric, F_commits,return.dm=TRUE)
print(res)
res = cliff.delta(MCC_commits, MCC_social, return.dm=TRUE)
print(res)
res = cliff.delta(MCC_numeric, MCC_social,return.dm=TRUE)
print(res)
res = cliff.delta(MCC_numeric, MCC_commits,return.dm=TRUE)
print(res)
res = cliff.delta(F_numeric, F_social,return.dm=TRUE)
print(res)
res = cliff.delta(F_numeric, F_commits,return.dm=TRUE)
print(res)
install.packages("rattle")
rattle()
rattle
rattle
rattle()
library(rattle)
rattle()
i=3
paste("graph",i,".png")
paste("graph",i,".png",sep = "")
Design<-c(70,24,22,34,80,93,37,02,14,17,88,67,56)
Dev<-c(22,33,56,79,68,40,34,98,78,65,76,43,21)
boxplot(Design~Dev)
boxplot(Design)
boxplot(Design,Dev)
install.packages("bstats")
library(bstats)
x = c(1,0)
n = c(72370,73058)
oddsratio(x,n=n)
Convictions <-
matrix(c(2, 10, 15, 3),
nrow = 2,
dimnames =
list(c("Dizygotic", "Monozygotic"),
c("Convicted", "Not convicted")))
Convictions
fisher.test(Convictions, conf.level = 0.95)$conf.int
x = matrix(c(2,10,17,13), ncol=2)
oddsratio(x)
Convictions <-
install.packages("bstats")
library(bstats)
install.packages("fmsb")
Convictions
Convictions <-
matrix(c(2, 10, 15, 3),
nrow = 2,
dimnames =
list(c("Dizygotic", "Monozygotic"),
c("Convicted", "Not convicted")))
Convictions
fisher.test(Convictions, conf.level = 0.95)$conf.int
x = matrix(c(2,10,17,13), ncol=2)
res <- oddsratio(x)
library(fmsb)
x = matrix(c(2,10,17,13), ncol=2)
res <- oddsratio(x)
View(x)
res <- oddsratio(2,10,17,13)
str(res)
print(res)
oddsratio(x)
Convictions <-
matrix(c(8, 492, 0, 500), nrow = 2, byrow=TRUE)
fisher.test(Convictions, conf.level = 0.95)$conf.int
oddsratio(8, 492, 0, 500)
fisher.test(Convictions, conf.level = 0.95)$conf.int
oddsratio(8, 492, 0, 500)
res <- oddsratio(2,10,17,13)
str(res)
print(res)
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
wilcox.test(commits_after$X..of.commits, commits_before$X..of.commits)
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
source('~/Dropbox/QuasiCasual/ScriptR/CollectingMergedUsersPRKubernetes.R')
